{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8710869,"sourceType":"datasetVersion","datasetId":5225573}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ”¥Text Generation - GPTðŸ”¥</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"![](https://jaid.io/wp-content/uploads/2023/08/Jaid_A-I-Z_G-is-for-GPT_1920x1080px-1600x900.png?x25671)","metadata":{}},{"cell_type":"markdown","source":"Here's an overview of GPT (Generative Pretrained Transformer) models using bullet and subbullet points:\n\n### GPT Models Overview\n\n- **Introduction to GPT Models**:\n  - GPT stands for Generative Pretrained Transformer.\n  - Developed by OpenAI, GPT models utilize the Transformer architecture for natural language processing tasks.\n\n- **Key Features**:\n  - **Unidirectional Transformer**: GPT models are based on a unidirectional Transformer decoder architecture, where each token is predicted based on previous tokens.\n  - **Pretraining**: Models are pretrained on large text corpora using unsupervised learning objectives, such as language modeling.\n  - **Fine-Tuning**: After pretraining, GPT models can be fine-tuned on specific downstream tasks with supervised learning.\n\n- **Architecture**:\n  - **Transformer Block**:\n    - Composed of multi-head self-attention mechanism and feedforward neural networks.\n    - Enables capturing global dependencies in text sequences.\n  - **Decoder-Only**:\n    - Unlike BERT (Bidirectional Encoder Representations from Transformers), GPT uses only the decoder part of the Transformer.\n    - Predicts each token sequentially, conditioned on previous tokens.\n\n- **Model Variants**:\n  - **GPT-1**: The original GPT model with 12 transformer layers and 117M parameters.\n  - **GPT-2**: Improved version with 48 transformer layers and 1.5B parameters, demonstrating better performance.\n  - **GPT-3**: Even larger model with 175B parameters, capable of more complex tasks and generating coherent human-like text.\n\n- **Applications**:\n  - **Text Generation**: GPT models excel in generating human-like text given a prompt or context.\n  - **Language Understanding**: Can be used for tasks like sentiment analysis, summarization, and question answering after fine-tuning.\n\n- **Advantages**:\n  - **Scalability**: GPT models can be scaled to larger sizes with more parameters, improving performance.\n  - **Generality**: Effective across various natural language processing tasks without task-specific architectures.\n  - **Transfer Learning**: Pretrained on vast amounts of text data, enabling efficient transfer learning to downstream tasks.\n\n- **Challenges**:\n  - **Computational Resources**: Large-scale GPT models require significant computational resources for training and inference.\n  - **Context Understanding**: Limited by the context window size, potentially missing long-range dependencies.\n\n- **Future Directions**:\n  - **Continual Learning**: Advancements in model training techniques for continuous learning without catastrophic forgetting.\n  - **Ethical Considerations**: Addressing biases and ethical implications in AI-generated text and understanding.\n\nThis outline provides a structured overview of GPT models, highlighting their architecture, applications, strengths, challenges, and future directions in the field of natural language processing.","metadata":{}},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ”—Related WorksðŸ”—</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<ul>\n<li>GitHub =&gt;\n<a href=\"https://github.com/Nishant2018\" rel=\" noreferrer nofollow\">GitHub</a>\n<br><br></li>\n<li>Text Generation Using GPT-2 =&gt;\n<a href=\"https://www.kaggle.com/code/endofnight17j03/textgeneration-transformers-gpt-2\">Text Generation</a>\n<br><br></li>\n<li>Text Mask Generation BERT Model =&gt;\n<a href=\"https://www.kaggle.com/code/endofnight17j03/text-mask-generation-googlebert-llm\">Text Mask Generation</a>\n<br><br></li>\n<li>Sentiment Analysis =&gt;\n<a href=\"https://www.kaggle.com/code/endofnight17j03/imdb-movies-nlp-sentiment-analysis\">Text Mask Generation</a></li>\n</ul>\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ“šImporting LibrariesðŸ“š</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"text-align:center\">\n    <img src=\"https://static.vecteezy.com/system/resources/thumbnails/013/083/739/small_2x/stick-man-with-book-shelves-in-library-education-and-learning-concept-3d-illustration-or-3d-rendering-png.png\n\" alt=\"Image\">\n</div>","metadata":{}},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:47:47.081825Z","iopub.execute_input":"2024-06-17T10:47:47.082164Z","iopub.status.idle":"2024-06-17T10:48:01.097417Z","shell.execute_reply.started":"2024-06-17T10:47:47.082136Z","shell.execute_reply":"2024-06-17T10:48:01.096437Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\nDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nimport re\nimport torch\nfrom torch import nn\nfrom torchsummary import summary\nfrom transformers import GPT2Tokenizer\nfrom tokenizers import ByteLevelBPETokenizer\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-17T10:48:08.557916Z","iopub.execute_input":"2024-06-17T10:48:08.558250Z","iopub.status.idle":"2024-06-17T10:48:13.958641Z","shell.execute_reply.started":"2024-06-17T10:48:08.558225Z","shell.execute_reply":"2024-06-17T10:48:13.957737Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/medium-articles/medium_articles.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div class=\"alert alert-block alert-success\" style=\"margin: 20px; padding: 20px; border-radius: 10px; border: 2px solid #4CAF50; background-color: #E6F7E2;\">\n    <b>ðŸ“‚ Libraries:</b> Successfully import the recquired library\n</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ“‚Reading The FileðŸ“‚</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"text-align:center\">\n    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Reading-297450.png/1280px-Reading-297450.png\n\" alt=\"Image\">\n</div>","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/medium-articles/medium_articles.csv')","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:48:50.775885Z","iopub.execute_input":"2024-06-17T10:48:50.776655Z","iopub.status.idle":"2024-06-17T10:49:15.881400Z","shell.execute_reply.started":"2024-06-17T10:48:50.776623Z","shell.execute_reply":"2024-06-17T10:49:15.880562Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ“šDataset SampleðŸ“š</div>\n</div>","metadata":{}},{"cell_type":"code","source":"df.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:49:40.952327Z","iopub.execute_input":"2024-06-17T10:49:40.952675Z","iopub.status.idle":"2024-06-17T10:49:40.976412Z","shell.execute_reply.started":"2024-06-17T10:49:40.952647Z","shell.execute_reply":"2024-06-17T10:49:40.975574Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                              title  \\\n0               Mental Note Vol. 24   \n1         Your Brain On Coronavirus   \n2                    Mind Your Nose   \n3          The 4 Purposes of Dreams   \n4  Surviving a Rod Through the Head   \n\n                                                text  \\\n0  Photo by Josh Riemer on Unsplash\\n\\nMerry Chri...   \n1  Your Brain On Coronavirus\\n\\nA guide to the cu...   \n2  Mind Your Nose\\n\\nHow smell training can chang...   \n3  Passionate about the synergy between science a...   \n4  Youâ€™ve heard of him, havenâ€™t you? Phineas Gage...   \n\n                                                 url                 authors  \\\n0  https://medium.com/invisible-illness/mental-no...            ['Ryan Fan']   \n1  https://medium.com/age-of-awareness/how-the-pa...       ['Simon Spichak']   \n2  https://medium.com/neodotlife/mind-your-nose-f...                      []   \n3  https://medium.com/science-for-real/the-4-purp...  ['Eshan Samaranayake']   \n4  https://medium.com/live-your-life-on-purpose/s...        ['Rishav Sinha']   \n\n                          timestamp  \\\n0  2020-12-26 03:38:10.479000+00:00   \n1  2020-09-23 22:10:17.126000+00:00   \n2  2020-10-10 20:17:37.132000+00:00   \n3  2020-12-21 16:05:19.524000+00:00   \n4  2020-02-26 00:01:01.576000+00:00   \n\n                                                tags  \n0  ['Mental Health', 'Health', 'Psychology', 'Sci...  \n1  ['Mental Health', 'Coronavirus', 'Science', 'P...  \n2  ['Biotechnology', 'Neuroscience', 'Brain', 'We...  \n3  ['Health', 'Neuroscience', 'Mental Health', 'P...  \n4  ['Brain', 'Health', 'Development', 'Psychology...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>url</th>\n      <th>authors</th>\n      <th>timestamp</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Mental Note Vol. 24</td>\n      <td>Photo by Josh Riemer on Unsplash\\n\\nMerry Chri...</td>\n      <td>https://medium.com/invisible-illness/mental-no...</td>\n      <td>['Ryan Fan']</td>\n      <td>2020-12-26 03:38:10.479000+00:00</td>\n      <td>['Mental Health', 'Health', 'Psychology', 'Sci...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Your Brain On Coronavirus</td>\n      <td>Your Brain On Coronavirus\\n\\nA guide to the cu...</td>\n      <td>https://medium.com/age-of-awareness/how-the-pa...</td>\n      <td>['Simon Spichak']</td>\n      <td>2020-09-23 22:10:17.126000+00:00</td>\n      <td>['Mental Health', 'Coronavirus', 'Science', 'P...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Mind Your Nose</td>\n      <td>Mind Your Nose\\n\\nHow smell training can chang...</td>\n      <td>https://medium.com/neodotlife/mind-your-nose-f...</td>\n      <td>[]</td>\n      <td>2020-10-10 20:17:37.132000+00:00</td>\n      <td>['Biotechnology', 'Neuroscience', 'Brain', 'We...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The 4 Purposes of Dreams</td>\n      <td>Passionate about the synergy between science a...</td>\n      <td>https://medium.com/science-for-real/the-4-purp...</td>\n      <td>['Eshan Samaranayake']</td>\n      <td>2020-12-21 16:05:19.524000+00:00</td>\n      <td>['Health', 'Neuroscience', 'Mental Health', 'P...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Surviving a Rod Through the Head</td>\n      <td>Youâ€™ve heard of him, havenâ€™t you? Phineas Gage...</td>\n      <td>https://medium.com/live-your-life-on-purpose/s...</td>\n      <td>['Rishav Sinha']</td>\n      <td>2020-02-26 00:01:01.576000+00:00</td>\n      <td>['Brain', 'Health', 'Development', 'Psychology...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:49:52.546947Z","iopub.execute_input":"2024-06-17T10:49:52.547310Z","iopub.status.idle":"2024-06-17T10:49:52.553174Z","shell.execute_reply.started":"2024-06-17T10:49:52.547281Z","shell.execute_reply":"2024-06-17T10:49:52.552320Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(192368, 6)"},"metadata":{}}]},{"cell_type":"code","source":"df = df.sample(90000)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:50:34.048441Z","iopub.execute_input":"2024-06-17T10:50:34.048814Z","iopub.status.idle":"2024-06-17T10:50:34.095374Z","shell.execute_reply.started":"2024-06-17T10:50:34.048785Z","shell.execute_reply":"2024-06-17T10:50:34.094486Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ¥¨Converting Into TextðŸ¥¨</div>\n</div>","metadata":{}},{"cell_type":"code","source":"summaries = df['text']\n\nwith open('Article.txt', 'w', encoding='utf-8') as file:\n    for summary in summaries:\n        file.write(summary + '\\n')","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:50:35.472341Z","iopub.execute_input":"2024-06-17T10:50:35.472990Z","iopub.status.idle":"2024-06-17T10:50:36.627520Z","shell.execute_reply.started":"2024-06-17T10:50:35.472955Z","shell.execute_reply":"2024-06-17T10:50:36.626743Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def read_text_file(file_path):\n    with open(file_path, 'r', encoding='utf-8') as file:\n        summaries = file.readlines()\n    return summaries\n\nfile_path = '/kaggle/working/Article.txt'\n\nArticle = read_text_file(file_path)\n\nfor i, summary in enumerate(Article[:5]):\n    print(f\"Summary {i+1}: {summary.strip()}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:50:37.846642Z","iopub.execute_input":"2024-06-17T10:50:37.847035Z","iopub.status.idle":"2024-06-17T10:50:40.057158Z","shell.execute_reply.started":"2024-06-17T10:50:37.847007Z","shell.execute_reply":"2024-06-17T10:50:40.056314Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Summary 1: in Both Sides of the Table\nSummary 2: This week is the first time I saw the Climate Clock in the flesh. Right by Union Square Park in New York City, there is effectively a doomsday clock counting down. When I saw it yesterday it told me that we have 6 yrs 270 days 08:26:41 to achieve zero emissions in order to prevent catastrophic consequences. In actuality, the clock doesnâ€™t mention the last part which is probably why unknowing people walk past it everyday. Nonetheless, regardless of whether you know what it indicates, it remains a powerful sight for anyone who looks upon it.\nSummary 3: \nSummary 4: So, we have six years. Six years to seriously change the way our planetâ€™s societies operate. But we knew that already, didnâ€™t we? So what has changed in the past five years? How is technology gearing to tackle this impending issue? Iâ€™ve spent a lot of time recently exploring those technologies at the forefront of innovation for climate change mitigation, and many give cause for hope.\nSummary 5: \n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ› PreprocessingðŸ› </div>\n</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"text-align:center\">\n    <img src=\"https://media.licdn.com/dms/image/C4D12AQHsdEIHnH7KNQ/article-cover_image-shrink_600_2000/0/1566722923152?e=2147483647&amp;v=beta&amp;t=YsmFCdp6hlGK7-8KYTadb6LXwKrnhBrmLlRt-RNfjIg\n\" alt=\"Image\">\n</div>","metadata":{}},{"cell_type":"code","source":"def clean_text(text):\n    text = re.sub(r'<[^>]+>', '', text)  \n    text = re.sub(r'\\s+', ' ', text)  \n    text = text.strip()\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:50:40.062621Z","iopub.execute_input":"2024-06-17T10:50:40.062964Z","iopub.status.idle":"2024-06-17T10:50:40.070013Z","shell.execute_reply.started":"2024-06-17T10:50:40.062937Z","shell.execute_reply":"2024-06-17T10:50:40.068722Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"cleaned_data = [clean_text(sample) for sample in Article]","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:50:42.397538Z","iopub.execute_input":"2024-06-17T10:50:42.398163Z","iopub.status.idle":"2024-06-17T10:51:34.325611Z","shell.execute_reply.started":"2024-06-17T10:50:42.398130Z","shell.execute_reply":"2024-06-17T10:51:34.324849Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"for i, summary in enumerate(cleaned_data[:5]):\n    print(f\"Summary {i+1}: {summary.strip()}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:51:34.327277Z","iopub.execute_input":"2024-06-17T10:51:34.327572Z","iopub.status.idle":"2024-06-17T10:51:34.332652Z","shell.execute_reply.started":"2024-06-17T10:51:34.327546Z","shell.execute_reply":"2024-06-17T10:51:34.331725Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Summary 1: in Both Sides of the Table\nSummary 2: This week is the first time I saw the Climate Clock in the flesh. Right by Union Square Park in New York City, there is effectively a doomsday clock counting down. When I saw it yesterday it told me that we have 6 yrs 270 days 08:26:41 to achieve zero emissions in order to prevent catastrophic consequences. In actuality, the clock doesnâ€™t mention the last part which is probably why unknowing people walk past it everyday. Nonetheless, regardless of whether you know what it indicates, it remains a powerful sight for anyone who looks upon it.\nSummary 3: \nSummary 4: So, we have six years. Six years to seriously change the way our planetâ€™s societies operate. But we knew that already, didnâ€™t we? So what has changed in the past five years? How is technology gearing to tackle this impending issue? Iâ€™ve spent a lot of time recently exploring those technologies at the forefront of innovation for climate change mitigation, and many give cause for hope.\nSummary 5: \n","output_type":"stream"}]},{"cell_type":"code","source":"def split_into_paragraphs(text):\n    return text.split('\\n\\n')\n\ndef split_into_sentences(text):\n    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n    return sentences\n\n# Split the text into paragraphs and then into sentences\nparagraphs = [split_into_paragraphs(sample) for sample in cleaned_data]\nsentences = [[split_into_sentences(paragraph) for paragraph in sample_paragraphs] for sample_paragraphs in paragraphs]\n\n# Flatten the nested list of sentences\nflattened_sentences = [sentence for sample_sentences in sentences for paragraph_sentences in sample_sentences for sentence in paragraph_sentences]","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:51:34.333765Z","iopub.execute_input":"2024-06-17T10:51:34.334023Z","iopub.status.idle":"2024-06-17T10:53:38.794154Z","shell.execute_reply.started":"2024-06-17T10:51:34.334000Z","shell.execute_reply":"2024-06-17T10:53:38.793362Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Debugging: Print the first few sentences to verify\nprint(flattened_sentences[:5])","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:53:38.796256Z","iopub.execute_input":"2024-06-17T10:53:38.796619Z","iopub.status.idle":"2024-06-17T10:53:38.801446Z","shell.execute_reply.started":"2024-06-17T10:53:38.796590Z","shell.execute_reply":"2024-06-17T10:53:38.800515Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"['in Both Sides of the Table', 'This week is the first time I saw the Climate Clock in the flesh.', 'Right by Union Square Park in New York City, there is effectively a doomsday clock counting down.', 'When I saw it yesterday it told me that we have 6 yrs 270 days 08:26:41 to achieve zero emissions in order to prevent catastrophic consequences.', 'In actuality, the clock doesnâ€™t mention the last part which is probably why unknowing people walk past it everyday.']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Join sentences with newline characters\nprocessed_text = '\\n'.join(flattened_sentences)\n\n# Save to a .txt file\nwith open('processed_text.txt', 'w', encoding='utf-8') as f:\n    f.write(processed_text)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:53:38.802698Z","iopub.execute_input":"2024-06-17T10:53:38.803009Z","iopub.status.idle":"2024-06-17T10:53:42.274283Z","shell.execute_reply.started":"2024-06-17T10:53:38.802980Z","shell.execute_reply":"2024-06-17T10:53:42.273271Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ”¥Tokenization - ByteLevelEncodingðŸ”¥</div>\n</div>\n</div>","metadata":{}},{"cell_type":"code","source":"tokenizer = ByteLevelBPETokenizer()\ntokenizer.train(files=[\"/kaggle/working/processed_text.txt\"], vocab_size=50257, min_frequency=2, special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"])","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:53:42.275604Z","iopub.execute_input":"2024-06-17T10:53:42.275983Z","iopub.status.idle":"2024-06-17T10:55:17.828427Z","shell.execute_reply.started":"2024-06-17T10:53:42.275950Z","shell.execute_reply":"2024-06-17T10:55:17.827585Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.save_model(\"/kaggle/working/\")","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:55:17.829581Z","iopub.execute_input":"2024-06-17T10:55:17.829864Z","iopub.status.idle":"2024-06-17T10:55:17.875583Z","shell.execute_reply.started":"2024-06-17T10:55:17.829839Z","shell.execute_reply":"2024-06-17T10:55:17.874646Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/vocab.json', '/kaggle/working/merges.txt']"},"metadata":{}}]},{"cell_type":"code","source":"# Example usage:\nencoded_text = tokenizer.encode(\"We just wanted everyone to know how much we appreciate everyone and how thankful we are for all our readers and writers here.\")\nprint(encoded_text.tokens)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:55:17.877124Z","iopub.execute_input":"2024-06-17T10:55:17.877627Z","iopub.status.idle":"2024-06-17T10:55:17.888547Z","shell.execute_reply.started":"2024-06-17T10:55:17.877582Z","shell.execute_reply":"2024-06-17T10:55:17.887524Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"['We', 'Ä just', 'Ä wanted', 'Ä everyone', 'Ä to', 'Ä know', 'Ä how', 'Ä much', 'Ä we', 'Ä appreciate', 'Ä everyone', 'Ä and', 'Ä how', 'Ä thankful', 'Ä we', 'Ä are', 'Ä for', 'Ä all', 'Ä our', 'Ä readers', 'Ä and', 'Ä writers', 'Ä here', '.']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ”¥GPT ModelsðŸ”¥</div>\n</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"![](https://www.kdnuggets.com/wp-content/uploads/mehra_deep_dive_gpt_models_1.png)","metadata":{}},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n  <div style=\"color:black; border: 2px solid #ff6347; background-color:#ff6347; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Arial', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7); box-shadow: 0 4px 8px rgba(0, 0, 0, 0.4);\">\n    GPT-2 Small Architecture\n  </div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"text-align:center\">\n    <img src=\"https://jalammar.github.io/images/gpt2/gpt2-sizes-hyperparameters-3.png\n\" alt=\"Image\">\n</div>","metadata":{}},{"cell_type":"code","source":"class GPT2Model(nn.Module):\n    def __init__(self, vocab_size, n_positions=1024, n_ctx=1024, n_embd=768, n_layer=12, n_head=12):\n        super(GPT2Model, self).__init__()\n        self.wte = nn.Embedding(vocab_size, n_embd)\n        self.wpe = nn.Embedding(n_positions, n_embd)\n        self.h = nn.ModuleList([nn.TransformerDecoderLayer(n_embd, n_head) for _ in range(n_layer)])\n        self.ln_f = nn.LayerNorm(n_embd)\n        self.head = nn.Linear(n_embd, vocab_size, bias=False)\n\n    def forward(self, input_ids, position_ids=None):\n        if position_ids is None:\n            position_ids = torch.arange(input_ids.size(1), dtype=torch.long, device=input_ids.device)\n            position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n        inputs_embeds = self.wte(input_ids) + self.wpe(position_ids)\n        hidden_states = inputs_embeds\n        for block in self.h:\n            hidden_states = block(hidden_states)\n        hidden_states = self.ln_f(hidden_states)\n        logits = self.head(hidden_states)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:55:17.889655Z","iopub.execute_input":"2024-06-17T10:55:17.889977Z","iopub.status.idle":"2024-06-17T10:55:17.934087Z","shell.execute_reply.started":"2024-06-17T10:55:17.889954Z","shell.execute_reply":"2024-06-17T10:55:17.933106Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model = GPT2Model(vocab_size=50257)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:55:17.937224Z","iopub.execute_input":"2024-06-17T10:55:17.937561Z","iopub.status.idle":"2024-06-17T10:55:19.828393Z","shell.execute_reply.started":"2024-06-17T10:55:17.937536Z","shell.execute_reply":"2024-06-17T10:55:19.827490Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"text-align:center\">\n    <img src=\"https://www.researchgate.net/publication/373352176/figure/fig1/AS:11431281202501967@1698856108167/GPT-2-model-architecture-The-GPT-2-model-contains-N-Transformer-decoder-blocks-as-shown.ppm\n\" alt=\"Image\">\n</div>","metadata":{}},{"cell_type":"code","source":"#tokenizer = ByteLevelBPETokenizer(\"merges.txt\", \"vocab.json\")","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:55:19.829519Z","iopub.execute_input":"2024-06-17T10:55:19.829828Z","iopub.status.idle":"2024-06-17T10:55:19.834103Z","shell.execute_reply.started":"2024-06-17T10:55:19.829803Z","shell.execute_reply":"2024-06-17T10:55:19.833192Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def tokenize_function(text):\n    # Encode the text using the tokenizer\n    encoded = tokenizer.encode(text)\n    \n    # Convert the encoded tokens to PyTorch tensors\n    input_ids = torch.tensor(encoded.ids).unsqueeze(0)  # Unsqueeze to add batch dimension\n    attention_mask = torch.tensor(encoded.attention_mask).unsqueeze(0)  # Unsqueeze to add batch dimension\n    \n    # Return the tokenized input as a dictionary of tensors\n    return {\n        'input_ids': input_ids,\n        'attention_mask': attention_mask\n    }","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:55:19.835260Z","iopub.execute_input":"2024-06-17T10:55:19.835536Z","iopub.status.idle":"2024-06-17T10:55:19.846749Z","shell.execute_reply.started":"2024-06-17T10:55:19.835512Z","shell.execute_reply":"2024-06-17T10:55:19.845975Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"tokenized_data = [tokenize_function(sample) for sample in processed_text]","metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:55:19.847856Z","iopub.execute_input":"2024-06-17T10:55:19.848130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\n\nclass TextDataset(Dataset):\n    def __init__(self, tokenized_data):\n        self.data = tokenized_data\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = TextDataset(tokenized_data)\ndataloader = DataLoader(dataset, batch_size=4, shuffle=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n\nmodel = GPT2Model(vocab_size=tokenizer.vocab_size)\noptimizer = optim.Adam(model.parameters(), lr=5e-5)\n\ndef train_model(model, dataloader, optimizer, epochs=3):\n    model.train()\n    for epoch in range(epochs):\n        for batch in dataloader:\n            input_ids = batch['input_ids'].squeeze(1)\n            optimizer.zero_grad()\n            outputs = model(input_ids)\n            shift_logits = outputs[..., :-1, :].contiguous()\n            shift_labels = input_ids[..., 1:].contiguous()\n            loss_fct = nn.CrossEntropyLoss()\n            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n            loss.backward()\n            optimizer.step()\n            print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n\ntrain_model(model, dataloader, optimizer)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_text(model, tokenizer, prompt, max_length=50):\n    model.eval()\n    input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"]\n    with torch.no_grad():\n        outputs = model.generate(input_ids, max_length=max_length, num_return_sequences=1)\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprompt = \"Once upon a time\"\nprint(generate_text(model, tokenizer, prompt))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained(\"path/to/save/model\")\ntokenizer.save_pretrained(\"path/to/save/tokenizer\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n  <div style=\"color:black; border: 2px solid #ff6347; background-color:#ff6347; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Arial', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7); box-shadow: 0 4px 8px rgba(0, 0, 0, 0.4);\">\n    GPT-1 Architecture\n  </div>\n</div>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}