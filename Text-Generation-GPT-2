{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ”¥Text Generation - GPTðŸ”¥</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"![](https://jaid.io/wp-content/uploads/2023/08/Jaid_A-I-Z_G-is-for-GPT_1920x1080px-1600x900.png?x25671)","metadata":{}},{"cell_type":"markdown","source":"Here's an overview of GPT (Generative Pretrained Transformer) models using bullet and subbullet points:\n\n### GPT Models Overview\n\n- **Introduction to GPT Models**:\n  - GPT stands for Generative Pretrained Transformer.\n  - Developed by OpenAI, GPT models utilize the Transformer architecture for natural language processing tasks.\n\n- **Key Features**:\n  - **Unidirectional Transformer**: GPT models are based on a unidirectional Transformer decoder architecture, where each token is predicted based on previous tokens.\n  - **Pretraining**: Models are pretrained on large text corpora using unsupervised learning objectives, such as language modeling.\n  - **Fine-Tuning**: After pretraining, GPT models can be fine-tuned on specific downstream tasks with supervised learning.\n\n- **Architecture**:\n  - **Transformer Block**:\n    - Composed of multi-head self-attention mechanism and feedforward neural networks.\n    - Enables capturing global dependencies in text sequences.\n  - **Decoder-Only**:\n    - Unlike BERT (Bidirectional Encoder Representations from Transformers), GPT uses only the decoder part of the Transformer.\n    - Predicts each token sequentially, conditioned on previous tokens.\n\n- **Model Variants**:\n  - **GPT-1**: The original GPT model with 12 transformer layers and 117M parameters.\n  - **GPT-2**: Improved version with 48 transformer layers and 1.5B parameters, demonstrating better performance.\n  - **GPT-3**: Even larger model with 175B parameters, capable of more complex tasks and generating coherent human-like text.\n\n- **Applications**:\n  - **Text Generation**: GPT models excel in generating human-like text given a prompt or context.\n  - **Language Understanding**: Can be used for tasks like sentiment analysis, summarization, and question answering after fine-tuning.\n\n- **Advantages**:\n  - **Scalability**: GPT models can be scaled to larger sizes with more parameters, improving performance.\n  - **Generality**: Effective across various natural language processing tasks without task-specific architectures.\n  - **Transfer Learning**: Pretrained on vast amounts of text data, enabling efficient transfer learning to downstream tasks.\n\n- **Challenges**:\n  - **Computational Resources**: Large-scale GPT models require significant computational resources for training and inference.\n  - **Context Understanding**: Limited by the context window size, potentially missing long-range dependencies.\n\n- **Future Directions**:\n  - **Continual Learning**: Advancements in model training techniques for continuous learning without catastrophic forgetting.\n  - **Ethical Considerations**: Addressing biases and ethical implications in AI-generated text and understanding.\n\nThis outline provides a structured overview of GPT models, highlighting their architecture, applications, strengths, challenges, and future directions in the field of natural language processing.","metadata":{}},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ”—Related WorksðŸ”—</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<ul>\n<li>GitHub =&gt;\n<a href=\"https://github.com/Nishant2018\" rel=\" noreferrer nofollow\">GitHub</a>\n<br><br></li>\n<li>Text Generation Using GPT-2 =&gt;\n<a href=\"https://www.kaggle.com/code/endofnight17j03/textgeneration-transformers-gpt-2\">Text Generation</a>\n<br><br></li>\n<li>Text Mask Generation BERT Model =&gt;\n<a href=\"https://www.kaggle.com/code/endofnight17j03/text-mask-generation-googlebert-llm\">Text Mask Generation</a>\n<br><br></li>\n<li>Sentiment Analysis =&gt;\n<a href=\"https://www.kaggle.com/code/endofnight17j03/imdb-movies-nlp-sentiment-analysis\">Text Mask Generation</a></li>\n</ul>\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ“šImporting LibrariesðŸ“š</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"text-align:center\">\n    <img src=\"https://static.vecteezy.com/system/resources/thumbnails/013/083/739/small_2x/stick-man-with-book-shelves-in-library-education-and-learning-concept-3d-illustration-or-3d-rendering-png.png\n\" alt=\"Image\">\n</div>","metadata":{}},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nimport re\nimport torch\nfrom torch import nn\nfrom termcolor import colored \nfrom torchsummary import summary\nfrom transformers import GPT2Tokenizer\nfrom tokenizers import ByteLevelBPETokenizer\nfrom torch.nn.utils import clip_grad_norm_\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div class=\"alert alert-block alert-success\" style=\"margin: 20px; padding: 20px; border-radius: 10px; border: 2px solid #4CAF50; background-color: #E6F7E2;\">\n    <b>ðŸ“‚ Libraries:</b> Successfully import the recquired library\n</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ“‚Reading The FileðŸ“‚</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"text-align:center\">\n    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Reading-297450.png/1280px-Reading-297450.png\n\" alt=\"Image\">\n</div>","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/medium-articles/medium_articles.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ“šDataset SampleðŸ“š</div>\n</div>","metadata":{}},{"cell_type":"code","source":"df.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.sample(1000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ¥¨Converting Into TextðŸ¥¨</div>\n</div>","metadata":{}},{"cell_type":"code","source":"summaries = df['text']\n\nwith open('Article.txt', 'w', encoding='utf-8') as file:\n    for summary in summaries:\n        file.write(summary + '\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_text_file(file_path):\n    with open(file_path, 'r', encoding='utf-8') as file:\n        summaries = file.readlines()\n    return summaries\n\nfile_path = '/kaggle/working/Article.txt'\n\nArticle = read_text_file(file_path)\n\nfor i, summary in enumerate(Article[:5]):\n    print(f\"Summary {i+1}: {summary.strip()}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ› PreprocessingðŸ› </div>\n</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"text-align:center\">\n    <img src=\"https://media.licdn.com/dms/image/C4D12AQHsdEIHnH7KNQ/article-cover_image-shrink_600_2000/0/1566722923152?e=2147483647&amp;v=beta&amp;t=YsmFCdp6hlGK7-8KYTadb6LXwKrnhBrmLlRt-RNfjIg\n\" alt=\"Image\">\n</div>","metadata":{}},{"cell_type":"code","source":"def clean_text(text):\n    text = re.sub(r'<[^>]+>', '', text)  \n    text = re.sub(r'\\s+', ' ', text)  \n    text = text.strip()\n    return text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned_data = [clean_text(sample) for sample in Article]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, summary in enumerate(cleaned_data[:5]):\n    print(f\"Summary {i+1}: {summary.strip()}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_into_paragraphs(text):\n    return text.split('\\n\\n')\n\ndef split_into_sentences(text):\n    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n    return sentences\n\n# Split the text into paragraphs and then into sentences\nparagraphs = [split_into_paragraphs(sample) for sample in cleaned_data]\nsentences = [[split_into_sentences(paragraph) for paragraph in sample_paragraphs] for sample_paragraphs in paragraphs]\n\n# Flatten the nested list of sentences\nflattened_sentences = [sentence for sample_sentences in sentences for paragraph_sentences in sample_sentences for sentence in paragraph_sentences]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Debugging: Print the first few sentences to verify\nprint(flattened_sentences[:5])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Join sentences with newline characters\nprocessed_text = '\\n'.join(flattened_sentences)\n\n# Save to a .txt file\nwith open('processed_text.txt', 'w', encoding='utf-8') as f:\n    f.write(processed_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ”¥Tokenization - ByteLevelEncodingðŸ”¥</div>\n</div>\n</div>","metadata":{}},{"cell_type":"code","source":"# Initialize the tokenizer\ntokenizer = ByteLevelBPETokenizer()\ntokenizer.train(files=[\"/kaggle/working/processed_text.txt\"], vocab_size=50257, min_frequency=2, special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.save_model(\"/kaggle/working/\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example usage:\nencoded_text = tokenizer.encode(\"We just wanted everyone to know how much we appreciate everyone and how thankful we are for all our readers and writers here.\")\nprint(encoded_text.tokens)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ“œ Dataset Preparation ðŸ“œ</div>\n</div>\n</div>","metadata":{}},{"cell_type":"code","source":"def tokenize_function(text):\n    encoded = tokenizer.encode(text)\n    input_ids = torch.tensor(encoded.ids).unsqueeze(0)\n    attention_mask = torch.tensor(encoded.attention_mask).unsqueeze(0)\n    return {\n        'input_ids': input_ids,\n        'attention_mask': attention_mask\n    }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_data = [tokenize_function(sample) for sample in processed_text]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_size = len(tokenizer.get_vocab()) \n\nprint(colored(f\"Original vocabulary size: {vocab_size}\", 'green'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\nclass TextDataset(Dataset):\n  def __init__(self, tokenized_data, max_len=512):  # Define a max_len for padding\n    self.data = tokenized_data\n    self.max_len = max_len\n\n  def __len__(self):\n    return len(self.data)\n\n  def __getitem__(self, idx):\n    sample = self.data[idx]\n    # Pad input_ids and attention_mask to the same length (max_len)\n    input_ids = sample['input_ids']\n    attention_mask = sample['attention_mask']\n    padded_input_ids = torch.nn.functional.pad(input_ids, (0, self.max_len - input_ids.shape[1]), value=0)\n    padded_attention_mask = torch.nn.functional.pad(attention_mask, (0, self.max_len - attention_mask.shape[1]), value=0)\n    return {\n        'input_ids': padded_input_ids,\n        'attention_mask': padded_attention_mask\n    }   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = TextDataset(tokenized_data, max_len=512)  # Set max_len for padding\ndataloader = DataLoader(dataset, batch_size=1, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ”¥GPT Models TrainingðŸ”¥</div>\n</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"![](https://www.kdnuggets.com/wp-content/uploads/mehra_deep_dive_gpt_models_1.png)","metadata":{}},{"cell_type":"markdown","source":"![](https://businessolution.org/wp-content/uploads/2022/06/word-image-2.png)","metadata":{}},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n  <div style=\"color:black; border: 2px solid #ff6347; background-color:#ff6347; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Arial', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7); box-shadow: 0 4px 8px rgba(0, 0, 0, 0.4);\">\n    GPT-1 Architecture\n  </div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"text-align:center\">\n    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Full_GPT_architecture.svg/800px-Full_GPT_architecture.svg.png\n\" alt=\"Image\">\n</div>","metadata":{}},{"cell_type":"code","source":"class GPT1Model(nn.Module):\n  def __init__(self, vocab_size, n_positions=512, n_embd=255, n_layer=2, n_head=3):\n    super(GPT1Model, self).__init__()\n    self.wte = nn.Embedding(vocab_size, n_embd)\n    self.wpe = nn.Embedding(n_positions, n_embd)\n    self.h = nn.ModuleList([nn.TransformerEncoderLayer(n_embd, n_head) for _ in range(n_layer)])\n    self.ln_f = nn.LayerNorm(n_embd)\n    self.linear = nn.Linear(n_embd, vocab_size)  \n\n  def forward(self, input_ids, position_ids=None):\n    if position_ids is None:\n      position_ids = torch.arange(input_ids.size(1), dtype=torch.long, device=input_ids.device)\n      position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n    inputs_embeds = self.wte(input_ids) + self.wpe(position_ids)\n    hidden_states = inputs_embeds\n    for block in self.h:\n      hidden_states = block(hidden_states)\n    hidden_states = self.ln_f(hidden_states)\n    logits = self.linear(hidden_states)  \n    return logits\n\n  def get_num_parameters(self):  \n    total_params = 0\n    for name, param in self.named_parameters():\n      if param.requires_grad:\n        total_params += param.numel()\n    return total_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpt_model = GPT1Model(vocab_size=vocab_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_params = gpt_model.get_num_parameters()\nprint(colored(f\"Number of trainable parameters in GPT-1: {num_params:,}\", 'green'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(colored(f\"Number of trainable parameters in GPT-1 is (24 Millions)\", 'red'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ngpt_model.to(device)\n#patience = 5  \n#best_val_loss = float('inf')\noptimizer = optim.Adam(gpt_model.parameters(), lr=5e-5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train_model(model, dataloader, optimizer, device, epochs=3):\n  model.train()\n  losses = []\n  for epoch in range(epochs):\n    with tqdm(total=len(dataloader), desc=f\"Epoch {epoch}\") as progress_bar:\n      for batch in dataloader:\n        input_ids = batch['input_ids'].squeeze(1).to(device)\n        optimizer.zero_grad()\n        outputs = model(input_ids)\n        shift_logits = outputs[..., :-1, :].contiguous()\n        shift_labels = input_ids[..., 1:].contiguous()\n        loss_fct = nn.CrossEntropyLoss()\n        loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n        loss.backward()\n        optimizer.step()\n        losses.append(loss.item())\n        # Update progress bar with current loss\n        progress_bar.set_postfix({'loss': loss.item()})  # Set 'loss' key-value pair\n        progress_bar.update(1)\n    print(f\"Epoch: {epoch}, Average Loss: {sum(losses) / len(losses)}\")\n  return losses","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpt_losses = train_model(gpt_model, dataloader, optimizer, device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n  <div style=\"color:black; border: 2px solid #ff6347; background-color:#ff6347; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Arial', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7); box-shadow: 0 4px 8px rgba(0, 0, 0, 0.4);\">\n    GPT-2 Small Architecture\n  </div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"text-align:center\">\n    <img src=\"https://jalammar.github.io/images/gpt2/gpt2-sizes-hyperparameters-3.png\n\" alt=\"Image\">\n</div>","metadata":{}},{"cell_type":"code","source":"class GPT2Model(nn.Module):\n    def __init__(self, vocab_size, n_positions=1024, n_ctx=1024, n_embd=768, n_layer=12, n_head=12):\n        super(GPT2Model, self).__init__()\n        self.wte = nn.Embedding(vocab_size, n_embd)\n        self.wpe = nn.Embedding(n_positions, n_embd)\n        self.h = nn.ModuleList([nn.TransformerEncoderLayer(n_embd, n_head) for _ in range(n_layer)])\n        self.ln_f = nn.LayerNorm(n_embd)\n        self.head = nn.Linear(n_embd, vocab_size, bias=False)\n\n    def forward(self, input_ids, position_ids=None):\n        if position_ids is None:\n            position_ids = torch.arange(input_ids.size(1), dtype=torch.long, device=input_ids.device)\n            position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n        inputs_embeds = self.wte(input_ids) + self.wpe(position_ids)\n        hidden_states = inputs_embeds\n        for block in self.h:\n            hidden_states = block(hidden_states)\n        hidden_states = self.ln_f(hidden_states)\n        logits = self.head(hidden_states)\n        return logits\n    def get_num_parameters(self):  # Define function inside the class\n        total_params = 0\n        for name, param in self.named_parameters():\n          if param.requires_grad:\n            total_params += param.numel()\n        return total_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpt2_model = GPT2Model(vocab_size=vocab_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_params = gpt2_model.get_num_parameters()\nprint(colored(f\"Number of trainable parameters in GPT-1: {num_params:,}\", 'green'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(colored(f\"Number of trainable parameters in GPT-1 is (144 Millions)\", 'red'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"text-align:center\">\n    <img src=\"https://www.researchgate.net/publication/373352176/figure/fig1/AS:11431281202501967@1698856108167/GPT-2-model-architecture-The-GPT-2-model-contains-N-Transformer-decoder-blocks-as-shown.ppm\n\" alt=\"Image\">\n</div>","metadata":{}},{"cell_type":"code","source":"#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ngpt2_model.to(device)\n\noptimizer = optim.Adam(gpt2_model.parameters(), lr=5e-5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train_model(model, dataloader, optimizer, device, epochs=3):\n  model.train()\n  losses = []\n  for epoch in range(epochs):\n    with tqdm(total=len(dataloader), desc=f\"Epoch {epoch}\") as progress_bar:\n      for batch in dataloader:\n        input_ids = batch['input_ids'].squeeze(1).to(device)\n        optimizer.zero_grad()\n        outputs = model(input_ids)\n        shift_logits = outputs[..., :-1, :].contiguous()\n        shift_labels = input_ids[..., 1:].contiguous()\n        loss_fct = nn.CrossEntropyLoss()\n        loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n        loss.backward()\n        optimizer.step()\n        losses.append(loss.item())\n        # Update progress bar with current loss\n        progress_bar.set_postfix({'loss': loss.item()})  # Set 'loss' key-value pair\n        progress_bar.update(1)\n    print(f\"Epoch: {epoch}, Average Loss: {sum(losses) / len(losses)}\")\n  return losses","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpt2_losses = train_model(gpt2_model, dataloader, optimizer, device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ”¥GPT Models PredictionðŸ”¥</div>\n</div>\n</div>","metadata":{}},{"cell_type":"code","source":"def generate_text(model, tokenizer, prompt, max_length=50):\n    model.eval()\n    input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"]\n    with torch.no_grad():\n        outputs = model.generate(input_ids, max_length=max_length, num_return_sequences=1)\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprompt = \"Once upon a time\"\nprint(generate_text(model, tokenizer, prompt))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:black; border: 2px solid #6f42c1; background-color:#f3e8ff; padding: 20px; border-radius: 15px; font-size: 200%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; text-align:center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\">ðŸ”¥GPT Models SavingðŸ”¥</div>\n</div>\n</div>","metadata":{}},{"cell_type":"code","source":"model.save_pretrained(\"path/to/save/model\")\ntokenizer.save_pretrained(\"path/to/save/tokenizer\")","metadata":{},"execution_count":null,"outputs":[]}]}